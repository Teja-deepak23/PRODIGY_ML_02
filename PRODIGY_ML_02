import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
# Load the dataset
data = pd.read_csv('path/to/your/customer_segmentation.csv')
# Display the first few rows of the dataset
print(data.head())

# Select relevant features (e.g., purchase history)
features = data[['Feature1', 'Feature2', 'Feature3']]  # Replace with actual feature names

# Handle missing values if necessary
features = features.fillna(features.mean())
# Scale the features
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
# Calculate WCSS (Within-Cluster Sum of Squares)
wcss = []
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(scaled_features)
    wcss.append(kmeans.inertia_)

# Plotting the Elbow graph
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()
# Create K-means model with optimal number of clusters (e.g., 4)
optimal_clusters = 4  # Adjust based on Elbow plot
kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)
kmeans.fit(scaled_features)

# Assign clusters to original data
data['Cluster'] = kmeans.labels_
# Display cluster centers and their corresponding features
cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)
centers_df = pd.DataFrame(cluster_centers, columns=['Feature1', 'Feature2', 'Feature3'])  # Adjust column names

print("Cluster Centers:")
print(centers_df)

# Visualize clusters (if applicable)
plt.scatter(scaled_features[:, 0], scaled_features[:, 1], c=kmeans.labels_, cmap='viridis')
plt.title('Customer Segments')
plt.xlabel('Feature1')
plt.ylabel('Feature2')
plt.show()
